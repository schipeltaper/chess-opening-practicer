<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Whisper and GPT Conversation</title>
</head>
<body>
    <h1>Whisper and GPT Conversation</h1>

    <!-- API Key Section -->
    <h2>Enter Your OpenAI API Key</h2>
    <form id="api-key-form">
        <label for="api-key">API Key:</label>
        <input type="password" id="api-key" name="api-key" required>
        <button type="submit">Save API Key</button>
    </form>
    <p id="api-status">API Key not set.</p>

    <!-- Recording Section -->
    <h2>Record Your Voice</h2>
    <button id="record-btn">Start Recording</button>
    <button id="submit-btn" disabled>Submit</button>
    <p id="status">Not recording</p>

    <!-- Conversation Section -->
    <h2>Conversation</h2>
    <p id="transcription-result">Transcription will appear here</p>
    <p id="gpt-response">GPT's response will appear here</p>

    <!-- Pause Button -->
    <button id="pause-btn" disabled>Pause Conversation</button>

    <script>
        let apiKey = '';
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob;

        const apiKeyForm = document.getElementById("api-key-form");
        const recordBtn = document.getElementById("record-btn");
        const submitBtn = document.getElementById("submit-btn");
        const pauseBtn = document.getElementById("pause-btn");
        const status = document.getElementById("status");
        const transcriptionResult = document.getElementById("transcription-result");
        const gptResponse = document.getElementById("gpt-response");

        // Handle API key submission
        apiKeyForm.addEventListener("submit", (event) => {
            event.preventDefault();
            const apiKeyInput = document.getElementById("api-key").value.trim();
            if (apiKeyInput) {
                apiKey = apiKeyInput;
                document.getElementById("api-status").textContent = "API Key set successfully.";
                apiKeyForm.reset();
            } else {
                alert("Please enter a valid API key.");
            }
        });

        // Handle recording functionality
        recordBtn.addEventListener("click", async () => {
            if (!mediaRecorder || mediaRecorder.state === "inactive") {
                try {
                    audioChunks = [];
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream);

                    mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
                    mediaRecorder.onstop = () => {
                        audioBlob = new Blob(audioChunks, { type: "audio/wav" });
                        status.textContent = "Recording stopped. Ready to submit.";
                        submitBtn.disabled = false;
                    };

                    mediaRecorder.start();
                    status.textContent = "Recording...";
                    recordBtn.textContent = "Stop Recording";
                } catch (err) {
                    console.error("Error accessing microphone:", err);
                    status.textContent = "Error: Unable to access microphone.";
                }
            } else {
                mediaRecorder.stop();
                recordBtn.textContent = "Start Recording";
            }
        });

        // Handle submission for STT and GPT
        submitBtn.addEventListener("click", async () => {
            if (!apiKey) {
                alert("Please set your API key first.");
                return;
            }

            if (!audioBlob) {
                alert("No recording found to process.");
                return;
            }

            status.textContent = "Processing audio...";
            const formData = new FormData();
            formData.append("audio", audioBlob);

            try {
                console.log("FormData:", formData.get("file"));

                // Step 1: Transcribe audio via Whisper API
                const sttResponse = await fetch("https://api.openai.com/v1/audio/transcriptions", {
                    method: "POST",
                    headers: {
                        Authorization: `Bearer ${apiKey}`,
                    },
                    body: formData,
                });

                if (!sttResponse.ok) {
                    throw new Error("Failed to transcribe audio.");
                }

                const sttResult = await sttResponse.json();
                const transcription = sttResult.text;
                transcriptionResult.textContent = `You said: ${transcription}`;

                // Step 2: Send transcription to GPT
                const gptResponseObj = await fetch("https://api.openai.com/v1/chat/completions", {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/json",
                        Authorization: `Bearer ${apiKey}`,
                    },
                    body: JSON.stringify({
                        model: "gpt-3.5-turbo",
                        messages: [{ role: "user", content: transcription }],
                    }),
                });

                if (!gptResponseObj.ok) {
                    throw new Error("Failed to get GPT response.");
                }

                const gptData = await gptResponseObj.json();
                const gptMessage = gptData.choices[0].message.content;
                gptResponse.textContent = `GPT says: ${gptMessage}`;

                // Step 3: Use TTS to read GPT response
                const ttsResponse = await fetch("/tts", {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/x-www-form-urlencoded",
                    },
                    body: new URLSearchParams({ text: gptMessage }),
                });

                if (!ttsResponse.ok) {
                    throw new Error("Failed to process TTS.");
                }

                const ttsBlob = await ttsResponse.blob();
                const ttsAudio = new Audio(URL.createObjectURL(ttsBlob));
                ttsAudio.play();

                status.textContent = "Conversation completed.";
                submitBtn.disabled = true;
                pauseBtn.disabled = false;
            } catch (error) {
                console.error("Error:", error);
                status.textContent = "An error occurred. Please try again.";
            }
        });

        // Pause conversation
        pauseBtn.addEventListener("click", () => {
            status.textContent = "Conversation paused.";
            transcriptionResult.textContent = "";
            gptResponse.textContent = "";
            audioBlob = null;
            submitBtn.disabled = true;
            pauseBtn.disabled = true;
        });
    </script>
</body>
</html>
